{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (14,14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Trees\n",
    "\n",
    "Trees can also perform regressions in addition to decisions. Using the regression tree models is pretty straightforward and very similar to any other model like linear regression. The regression tree itself is mostly similar to the decision tree, the primary difference is that both the outcomes and the error metrics are adapted to numerical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_to_df(sklearn_dataset):\n",
    "    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)\n",
    "    df['target'] = pd.Series(sklearn_dataset.target)\n",
    "    return df\n",
    "\n",
    "df = sklearn_to_df(sklearn.datasets.load_boston())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Model\n",
    "df2 = pd.get_dummies(df, drop_first=True)\n",
    "y = np.array(df2[\"target\"]).reshape(-1,1)\n",
    "X = np.array(df2.drop(columns={\"target\"}))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "clf = DecisionTreeRegressor()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(clf.get_depth())\n",
    "print(clf.score(X_test, y_test))\n",
    "plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Tree Decision Making\n",
    "\n",
    "The regression tree works very similarly to the decision tree. The key differences are:\n",
    "<ul>\n",
    "<li>Instead of producing a classification at the end, it produces an average of all the values in that group. That average is the prediction for anything that falls into that leaf on the tree. \n",
    "<li>Instead of using the information gain concept that decision trees do, a regression tree tries to minimize error when splitting, normally MSE. So the algorithm seeks splits that have the lowest average error between the error and the values.\n",
    "</ul>\n",
    "\n",
    "Just like decision trees, there are a few options that we can set as HP - one of those being the error metric. We can choose absolute error or a couple of others for the error metric; we can also set limits to growth like depth and min_split_size. \n",
    "\n",
    "#### Tree Weakness\n",
    "\n",
    "One specific weakness with regression trees is that they don't \"extend\" like a linear regression, they're bounded by whatever data they have. So if the maximum prediction that is generated in training is 50, no matter what future inputs look like it will never be able to predict beyond that. We can see this if we chart an example, there isn't a nice smooth prediction curve like a linear regression, we get blocky steps.\n",
    "\n",
    "![Regression Tree](images/regtree2.png \"Regression Tree\" )\n",
    "\n",
    "### Use a Grid Search to Improve\n",
    "\n",
    "We can also utilize a grid search to do some HP tuning. Along with some other options we can try different error metrics, I just copied the entire list from the sklearn page. Note that the names for absolute and squared error are changing, so depending on the specific version of sklearn you have installed you might need to use absolute_error/squared_error or mae/mse, the meaning is the same, they just changed the label to be more descriptive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_para = {'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "            'max_depth':[7,8,9,10,11,12,13,14,15,16], \n",
    "            'criterion':[\"friedman_mse\", \"poisson\", \"mse\", \"mae\"]}\n",
    "\n",
    "clfCV = GridSearchCV(estimator=DecisionTreeRegressor(), param_grid=tree_para, cv=10) #See below for the CV argument\n",
    "clfCV.fit(X_train, y_train)\n",
    "clfCV.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the optimal combo from above and create a new model. We could have also grabbed the best from above. The attribute \"best_estimator_\" is the most accurate model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeRegressor(max_depth=7, min_samples_split=8)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "print(clf2.score(X_test, y_test))\n",
    "plot_tree(clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Predictions\n",
    "\n",
    "We can look at the predictions made by the tree (limit the tree size to make the chart above and the results obvious). Predictions are only at the results of one of the terminal leafs, we don't get a curve like a linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf2.predict(X_test)\n",
    "sns.histplot(preds, binwidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worked Example, with a Forest\n",
    "\n",
    "Use a forest, pipeline, and gridsearchCV to predict the bodyfat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df_ = pd.read_csv(\"data/bodyfat.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml3950': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
