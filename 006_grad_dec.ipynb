{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import linear_reg_demo_grad_desc\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Redux and Cost\n",
    "\n",
    "We covered linear regression quite a bit in stats, it is one of the most simple and intuitive methods to make a predictive model - one that most of us did intuitively when doing a best fit line back in math class. \n",
    "\n",
    "The linear regression process we looked at used the algorithm of Linear Least Squares, which tries to create a model (the line) that has the lowest average squared distance from all the points. That is, the MSE between the model and the real values is a measurement of \"badness\" of the model - the smaller this value is, the better the model. We can also think of this MSE calculation as something called a Cost Function - the higher the cost, the worse the model is. \n",
    "\n",
    "The fitting part of a linear regression model is an attempt to minimize this cost function. The algorithm looks for the parameters (not hyperparameters) that minimize the cost; in a linear regression those parameters are the coefficients and the y-intercept. \n",
    "\n",
    "The linear least sqaures can calculate this directly, so the process of \"looking\" for the minimum is only one step. If you think back to logistic regression we can see a more dramatic example, the algorithm needs to test, try, and repeat. A decision tree is another example, the gini/entropy is the cost, and the algorithm searches through all potential splits until it finds the one that is best. That type of iteritive process is really common. \n",
    "\n",
    "### Cost Functions\n",
    "\n",
    "The idea of cost is something that we will use throughout machine learning, it is critical for setting a goal that the algorithm can aim for when training. The cost function is just some function that measures the amount of error in a model, the lower the cost, the better a model we have. Usually this cost function is something that is a regular error metric that we have seen before - something like mean squared error for regression problems and accuracy or, more likely, cross-entropy for classifications. The cost to use is often something that we can specify as a hyperparameter when we create our models, such as the choice between gini and entropy in a tree. \n",
    "\n",
    "The cost function does not inherently need to be a regular error calculation, it could be almost any calculation at all. In certain weird situations the \"goodness\" of a model might not be measured accurately by a normal error calculation. Suppose you made a model to predict things on The Price is Right (https://priceisright.fandom.com/wiki/One_Bid); you want the model to make predictions that are close to the real price (probably well measured by MSE), however if the model predicts a price that is over, that's a tragedy and needs to be penalized severely. Maybe you'd want a model that calculated something more odd - MSE if the prediction is less than the real value, and residual^4 is the prediction is higher. \n",
    "\n",
    "#### Linear Regression Cost Function\n",
    "\n",
    "The cost function is just our old friend the Mean Squared Error:\n",
    "\n",
    "![Linear Regression Cost](images/lin_reg_cost.png \"Linear Regression Cost\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate some random data\n",
    "X1 = 2 * np.random.rand(1000, 1)\n",
    "y1 = 4 + 3 * X1**3 + 3*np.random.randn(1000, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a simple linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg = lin_reg.fit(X1, y1)\n",
    "\n",
    "preds1 = lin_reg.predict(X1)\n",
    "d1 = pd.DataFrame(X1, columns={\"X\"})\n",
    "d1[\"Y_pred\"] = preds1\n",
    "d1[\"Y_real\"] = y1\n",
    "sns.lineplot(data = d1, x=\"X\", y=\"Y_pred\", color=\"red\")\n",
    "sns.scatterplot(data=d1, x=\"X\", y=\"Y_real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Results\n",
    "\n",
    "If we plot some data and generate a regression above, we have a solution that minimizes our cost function. There is no other model that we can create that has a lower mean squared residual between the model's predictions and the real values. Calculating the optimal model like we do here is great, however there are a couple of issues with that:\n",
    "\n",
    "<ul>\n",
    "<li>The computation cost when we have lots of data can become very large - growing exponentially. This can really matter when data grows massive. \n",
    "<li>Models that are not linear regression often can't be directly calculated (such as logistic regression). This is very common and we'll use gradient descent for things like neural networks later on. \n",
    "</ul>\n",
    "\n",
    "To deal with situations where we can't directly compute the optimal solution we need a different approach. Rather than determining the correct solution directly, we will make an attempt, evaluate the cost, make a slightly different attempt, and try to improve until we can't find a better cost score with subsequent attempts. This approach is called...\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "Gradient descent is a common approach to hunt for optimal solutions through an iteritive process. The process we can follow is:\n",
    "\n",
    "<ul>\n",
    "<li>Make an initial attempt to create a model, calculate the cost. This starting point is often random. \n",
    "<li>Compute the gradient - the derivitive or slope of the curve at that point. This indicates which direction to move. \n",
    "<li>Adjust the previous attempt, calculate the cost, compare to previous. The adjustment amount is determined by a value called the learning rate. \n",
    "<li>Repeat the previous step until moving does not improve the cost.\n",
    "</ul>\n",
    "\n",
    "We can visualize this process by looking at a curve of the cost function, and thinking about its derivitive or the slope. The gradient tells us two things:\n",
    "<ul>\n",
    "<li>Have we reached the best solution? If so, the gradient will be 0 indicating that we are at the minimum point on the curve. (i.e. there is no slope = we are at the bottom)\n",
    "<li>Which direction to go? We always want to go down the curve.\n",
    "</ul>\n",
    "\n",
    "![Gradient Descent](images/grad_desc.png \"Gradient Descent\" )\n",
    "\n",
    "When we've \"settled\" at the bottom, that is the lowest amount of cost, so there are no moves to make to find a better model. \n",
    "\n",
    "#### Gradient Descent - From Scratch\n",
    "\n",
    "We can illustrate how gradient descent works. The file linear_reg_demo_grad_desc.py has an implementation of a linear regression that does gradient descent. I have modified it to return the set of predictions for each step of the training process. So what is happening in the background is:\n",
    "<ul>\n",
    "<li>Generate a linear regression. \n",
    "<li>Calculate the gradients.\n",
    "<li>Update the weights to move against the gradient (down the curve).\n",
    "<ul>\n",
    "<li>The size of the jump is defined by the learning rate. Big rate, big move!\n",
    "</ul>\n",
    "<li>Repeat until the trials are done. (In real implementations you'll also stop when improvement ends.)\n",
    "</ul>\n",
    "\n",
    "This example is what is called Batch Gradient Descent - at every step the entire process is recalculated. \n",
    "\n",
    "Play around with the learning rates and iterations and see how it progresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "#Play around with some options and see the results!\n",
    "learn_rate = .05 #Learning rate - how large to move each update.\n",
    "iterations = 100 #How many iterations to run. \n",
    "num_show = 10 #How ofen to chart the line, i.e. 1 = every prediction, 10 = every 10th, etc.. \n",
    "\n",
    "train_rmses = []\n",
    "test_rmses =[]\n",
    "iters = []\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1)\n",
    "linreg = linear_reg_demo_grad_desc.LinearRegressionDemo(learning_rate=learn_rate, n_iters=iterations)\n",
    "preds, test_preds = linreg.fit(X_train, y_train.ravel(), X_test)\n",
    "sns.scatterplot(data=d1, x=\"X\", y=\"Y_real\")\n",
    "for i in range(len(preds)):\n",
    "    d_tmp = pd.DataFrame(X_train, columns={\"X\"})\n",
    "    d_tmp[\"Y_pred\"] = preds[i]\n",
    "    iters.append(i)\n",
    "    train_err = mean_squared_error(y_train, preds[i])\n",
    "    train_rmses.append(train_err)\n",
    "    test_err = mean_squared_error(y_test, test_preds[i])\n",
    "    test_rmses.append(test_err)\n",
    "    label = str(i) + \" - RMSE:\" + str(round(train_err, 3))\n",
    "    if (i%num_show) == 0:\n",
    "        sns.lineplot(data = d_tmp, x=\"X\", y=\"Y_pred\", label=label)\n",
    "d_iters = pd.DataFrame(iters, columns={\"Iteration\"})\n",
    "d_iters[\"Train\"] = train_rmses\n",
    "d_iters[\"Test\"] = test_rmses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Code Bits\n",
    "\n",
    "We can look at the .py file and examine some of the key bits (you can open it directly for details and full code)\n",
    "\n",
    "<b>perform gradient descent for n iterations</b>\n",
    "\n",
    "```python\n",
    "for _ in range(self.n_iters):\n",
    "    # get y_prediction\n",
    "    y_pred = self._get_prediction(X)\n",
    "    # compute gradients\n",
    "    dw, db = self._get_gradients(X, y, y_pred)\n",
    "    # update weights & bias with gradients\n",
    "    self._update_params(dw, db)\n",
    "```\n",
    "Here the fit function is pretty simple, we make a prediction, take that prediction to compute the gradients (slopes), then make and update to the weights...\n",
    "\n",
    "```python\n",
    "def _update_params(self, dw, db):\n",
    "    self.weights -= self.lr * dw\n",
    "    self.bias -= self.lr * db\n",
    "```\n",
    "Updating the weights is just incrementing them by the amount of the learning rate. \n",
    "\n",
    "```python\n",
    "def _get_gradients(self, X, y, y_pred):\n",
    "    # get distance between y_pred and y_true\n",
    "    error = y_pred - y\n",
    "    # compute the gradients of weight & bias\n",
    "    dw = (1 / self.n_samples) * np.dot(X.T, error)\n",
    "    db = (1 / self.n_samples) * np.sum(error)\n",
    "    return dw, db\n",
    "```\n",
    "Calculating the gradients is just a recalculation of the gradients at our new point on the cost curve. The math uses vector math (dot products) that we can ignore for now. \n",
    "\n",
    "So the overall process, repeated for N iterations is to create a prediction (make a linear regression model), calculate the gradients on the cost curve at that point, update our position based on the position by the amount of the learning rate, and repeat. Eventually we will reach a point where the gradients, the slope of the location on the cost curve, is 0, then we won't be updating anymore - think about why by looking at the _update_params function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Errors\n",
    "\n",
    "We can visualize the errors by iteration, or epoch as it is often called. Here we can see how long it takes for us to narrow in on a solution. \n",
    "\n",
    "I've graphed both the test and train errors, here they tend to be extremely close and often flip-flop in terms of accuracy depending on random splits. This is not a constant pattern, it is due to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.lineplot(data=d_iters, x=\"Iteration\", y=\"Train\", label=\"Train\")\n",
    "sns.lineplot(data=d_iters, x=\"Iteration\", y=\"Test\", label=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm will work its way towards the solution. \n",
    "\n",
    "### Errors and Gradients\n",
    "\n",
    "For a simple linear regression with one feature like we have here, the challenge is pretty simple. Our cost will be convex (shaped like a bowl), and we will always be able to find some solution, even if it takes a long time. With more complex datasets this isn't always true, we don't have a simple 2D curve, we have something that is in X dimension - maybe 100 or more at times. We can end up with curves that resemble this:\n",
    "\n",
    "![Complex Gradient Descent](images/comp_grad_desc.png \"Complex Gradient Descent\" )\n",
    "\n",
    "Here we have things like a local minima - a point at which the cost is minimized, but only locally, not overall. We don't want the algorithm to get 'stuck' in one of these holes, because we'll find a low cost, but not the lowest. \n",
    "\n",
    "Dealing with issues like this is there the learning rate comes in. By ensuring the learning rate is large enough, we have our attempts 'jump around' a little. This results in progress towards the minimum cost that is a little slower, but it also gives the function the ability to 'jump out' of problems like local minima. There's a balance with the learning rate, not too high, not too low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Types of Descents\n",
    "\n",
    "Batch gradient descent, like we did in the demo, suffers from the drawback that there is a lot of math involved in calculating the gradients, this can be slow with large amounts of data. In practice, there are a couple of things that we can do to speed this up. \n",
    "\n",
    "In the sample each time we iterated we calculated all of those gradients. For simple 2 varible datasets that's no big deal, but when the data gets massive, that's pretty slow. There are other implementations of gradient descent that apply the same concept, but take some shortcuts to lessen the amount of calculations needed. We can visualize how each 'hunts' the solution - the batch descent progresses steadily, the stochastic jumps around semi-randomly, and the mini-batch is between the two:\n",
    "\n",
    "![Gradient Descent Patterns](images/grad_desc_patterns.png \"Gradient Descent Patterns\" )\n",
    "\n",
    "#### Stochastic Gradient Descent\n",
    "\n",
    "Stochastic (randomized) Gradient Descent, or SGD, speeds things up by just randomly selecting an instance and using that for the gradient calculation. The speed up comes from that massive reductions in the number of gradients calculated - instead of doing it for each record, SGD does it only once. Much faster. \n",
    "\n",
    "The downside to this is that there is much more randomness, and progress towards the solution isn't linear since you might randomly choose a point that is out of the way. This introduces some noise to the process, but the savings in computation time makes it generally worth it. \n",
    "\n",
    "#### Mini Batch Gradient Descent\n",
    "\n",
    "MBGD combines the ideas of batch and SGD - at each step a small random subset of the data is used for the gradient calculations. \n",
    "\n",
    "#### Gradients and Outcomes\n",
    "\n",
    "Note that the idea of all these algoritms is to generate a final model that is nearly the same, only the path there is different. Gradient descent isn't attempting to find a better model than linear regression (in a regular linear regression we can calculate the best model in a closed for solution), it is attempting to use a different method to reach that goal model. This idea of \"narrowing in\" on a solution can become even more useful when we don't have a solution that can be directly calculated - as long as we can set the cost function that defines accuracy, we can work our way towards an optimal solution. \n",
    "\n",
    "\n",
    "\n",
    "![Gradient Descent Outcomes](images/grad_desc_usage.png \"Gradient Descent Outcomes\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD in Practice\n",
    "\n",
    "We do not need to implement this descent process by hand in practice, we can use the built in SKlearn modules, and the idea is also built into several other algorithms. For linear regression we can use SGDregressor, a generic implementation of SGD.\n",
    "\n",
    "\n",
    "We can do some gradient descent with actual data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/bodyfat.csv\")\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Datasets\n",
    "y2 = np.array(df[\"BodyFat\"]).reshape(-1,1)\n",
    "X2 = np.array(df.drop(columns={\"BodyFat\"}))\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Control Sample\n",
    "\n",
    "We can generate a standard linear regression model first, and see what the results are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closed Form Linear Regression\n",
    "pipe_LR_steps = [('scale', MinMaxScaler()), ('model', LinearRegression())]\n",
    "pipe_LR = Pipeline(pipe_LR_steps)\n",
    "\n",
    "start = time.process_time()\n",
    "pipe_LR.fit(X_train2, y_train2)\n",
    "print(time.process_time() - start)\n",
    "\n",
    "print('Training CrossVal Score:', cross_val_score(pipe_LR, X_train2, y_train2, cv=5))\n",
    "print('Testing score:', pipe_LR.score(X_test2, y_test2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regression\n",
    "\n",
    "Now we can create a model using gradient descent. There are a few options that we can specify in the SGD that are important:\n",
    "<ul>\n",
    "<li>eta0 - the initial learning rate. \n",
    "<li>learning_rate - how the learning rate is managed. In the examples we made by hand, the learning rate was constant. The SGD implementation provides for a way to adapt the learning rate - as you get closer to a solution, the learning rate slows. The defult is \"invscaling\", defined as: eta = eta0 / pow(t, power_t). t = number of updates, power_t = the exponent for inverse scaling learning rate.\n",
    "<ul>\n",
    "<li>This has the effect of using large learning rates to quickly narrow down to a close solution, hopefully taking advantage of both that speed increase and the ability to \"jump\" out of local minima. As the algorithm progresses, the rate slows to close in directly on a solution. \n",
    "</ul>\n",
    "<li>early_stopping - should the algorithm stop when it fails to improve. This will set aside a validation dataset, and if predictions for this set stop improving, end the training. If we look back to the demo, at some point the error flattens out and doesn't change much, early stopping stops at this point. We'll look at early stopping in more detail later on. \n",
    "<li>penalty - SGD applies regularization by default, which we'll discuss next time.\n",
    "</ul>\n",
    "\n",
    "<b>Note: Scaling values is very important in SGD algorithms. We'll probably get poor results if we forget.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD Regressor. \n",
    "pipe_SGD_steps = [('scale', MinMaxScaler()), ('model', SGDRegressor(max_iter=10000, eta0=.1))]\n",
    "pipe_SGD = Pipeline(pipe_SGD_steps)\n",
    "\n",
    "start = time.process_time()\n",
    "pipe_SGD.fit(X_train2, y_train2.ravel())\n",
    "print(time.process_time() - start)\n",
    "\n",
    "#Print best model and test score\n",
    "print('Training CrossVal Score:', cross_val_score(pipe_SGD, X_train2, y_train2.ravel(), cv=5))\n",
    "print('Testing score:', pipe_SGD.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the two examples above I added a timer. Play around with the learning rate and see what impact it has on the speed of SGD as compared to regular linear regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Example\n",
    "\n",
    "Predict car prices using an SGD Regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"data/CarPrice_Assignment.csv\")\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe/info data - look for data types as compared with dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: There is probably a large amount of multicollinearity here. We'll try this example again with regularization soon, which is one way to deal with it in practice</b>\n",
    "\n",
    "Also, depending on randomness there may be a need to deal with rare categorical values. Keep this in mind, you should be able to find 2+ solutions by Googling the error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start to preprocess and model. \n",
    "# Use columnn transformer as there are mixed feature types\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml3950': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
