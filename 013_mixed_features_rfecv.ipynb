{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.feature_selection import RFECV, SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection with Column Transformer\n",
    "\n",
    "Categorical and numerical variables need to be treated differently some times. We can loop back to the pipeline and column transformer stuff to incorporate the newer feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/mtcars.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Types\n",
    "\n",
    "For this, I am going to treat # of cylinders, vs, am, # of gears, and carb as categorical. This is a reasonable, but not necissarily correct, interpretation of the scenario - a domain knowledge decision.\n",
    "\n",
    "The data doesn't matter much here, and the example is tiny, but the feature selection stuff transfers as is to other datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 12 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   model   32 non-null     object  \n",
      " 1   mpg     32 non-null     float64 \n",
      " 2   cyl     32 non-null     category\n",
      " 3   disp    32 non-null     float64 \n",
      " 4   hp      32 non-null     int64   \n",
      " 5   drat    32 non-null     float64 \n",
      " 6   wt      32 non-null     float64 \n",
      " 7   qsec    32 non-null     float64 \n",
      " 8   vs      32 non-null     category\n",
      " 9   am      32 non-null     category\n",
      " 10  gear    32 non-null     category\n",
      " 11  carb    32 non-null     category\n",
      "dtypes: category(5), float64(5), int64(1), object(1)\n",
      "memory usage: 2.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Manually set categories as categories\n",
    "df[\"cyl\"] = df[\"cyl\"].astype(\"category\")\n",
    "df[\"vs\"] = df[\"vs\"].astype(\"category\")\n",
    "df[\"am\"] = df[\"am\"].astype(\"category\")\n",
    "df[\"gear\"] = df[\"gear\"].astype(\"category\")\n",
    "df[\"carb\"] = df[\"carb\"].astype(\"category\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Pipeline\n",
    "\n",
    "We have two pipelines that are then combined in our column transformer. The numerical one includes some rfecv to do feature selection on those variables. The categorical one includes k-best to do feature selection there. Each subset is feature selected, then the two subsets are combined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -0.16868065403596688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akeems/opt/anaconda3/envs/ml3950/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Data Split\n",
    "cat_feat = [\"cyl\", \"vs\", \"am\", \"gear\", \"carb\"]\n",
    "num_feat = [\"disp\", \"hp\", \"drat\", \"wt\", \"qsec\"]\n",
    "y = df[\"mpg\"]\n",
    "X = df.drop(columns={\"mpg\", \"model\"})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#estimators\n",
    "model = LinearRegression()\n",
    "selector = Lasso()\n",
    "\n",
    "# RFECV on Numerical Data\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "rfecv = RFECV(\n",
    "    estimator=selector,\n",
    "    step=1,\n",
    "    cv=3,\n",
    "    min_features_to_select=min_features_to_select,\n",
    ")\n",
    "num_pipe = Pipeline([ \n",
    "                (\"rfecc\", rfecv)                          \n",
    "])\n",
    "\n",
    "# KBest on Categorical Data\n",
    "kbest = SelectKBest(k=2)\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "                (\"kbest\",kbest)\n",
    "])\n",
    "\n",
    "#Pre-processing and Column Transformer\n",
    "prepro = ColumnTransformer([\n",
    "                (\"cat\", cat_pipe, cat_feat),\n",
    "                (\"num\", num_pipe, num_feat)\n",
    "])\n",
    "\n",
    "pipe = Pipeline([(\"prepro\", prepro), \n",
    "                (\"model\", model)    \n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Score:\", pipe.score(X_test, y_test))\n",
    "#print(pipe.get_params(\"steps\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Caveats\n",
    "\n",
    "This evaluates the features in two separate groups, and selects the strongest in each group. There is a possibility that there's some categorical-numerical combo of variables that is a great predictor filtered out, but that's pretty unlikely. \n",
    "\n",
    "You can also put in any transformations to the categorical and numerical pipes, like we did previously. I left them with only one step for clarity, but if you need to encode, scale, etc... all that stuff can just be layered in to those pipes. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml3950': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
